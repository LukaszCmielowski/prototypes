{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a12d957a-c313-4e92-9578-44f6a48560d5",
      "metadata": {},
      "source": [
        "<img src=\"data:image/svg+xml;base64,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\" width=\"100%\" alt=\"AutoML Banner\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e9aa72f-content",
      "metadata": {},
      "source": [
        "## Notebook content\n",
        "\n",
        "This notebook monitors Kubeflow Pipelines (KFP) runs for an AutoML experiment, displays the leaderboard, and optionally downloads a trained model to load and run predictions. It aligns with the **experiment** side of the pipeline (run details, leaderboard, model download).\n",
        "\n",
        "üí° **Tips:**\n",
        "- Ensure the KFP connection is configured (e.g. `KF_PIPELINES_SA_TOKEN_PATH`, `BEARER_TOKEN`) so the notebook can list runs and experiments.\n",
        "- Ensure the S3 connection is configured for the leaderboard and model download (e.g. `AWS_S3_ENDPOINT`, `AWS_S3_BUCKET`).\n",
        "- Set `experiment_name` and `run_name` to match your pipeline experiment and run.\n",
        "\n",
        "### Contents\n",
        "This notebook contains the following parts:\n",
        "\n",
        "**[Setup](#setup)**  \n",
        "**[Run AutoML experiment pipeline](#run-automl-experiment-pipeline)**  \n",
        "**[Monitor KFP run details](#monitor-kfp-run-details)**  \n",
        "**[Display leaderboard](#display-leaderboard)**  \n",
        "**[Download trained model](#download-trained-model)**  \n",
        "**[Load the model](#load-the-model)**  \n",
        "**[Summary and next steps](#summary-and-next-steps)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7d9cf2b-setup",
      "metadata": {},
      "source": [
        "<a id=\"setup\"></a>\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f578037e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "run-automl-pipeline",
      "metadata": {},
      "source": [
        "<a id=\"run-automl-experiment-pipeline\"></a>\n",
        "## Run AutoML experiment pipeline\n",
        "\n",
        "This section shows how to **submit** a new run of the AutoGluon tabular training pipeline. The pipeline is defined in the **pipelines-components** repository:\n",
        "\n",
        "`pipelines-components/pipelines/training/automl/autogluon_tabular_training_pipeline`\n",
        "\n",
        "It loads data from S3, trains AutoGluon models, selects the top N, refits them on the full dataset, and produces a leaderboard. You can then use **Monitor KFP run details** to track the run and **Display leaderboard** / **Download trained model** once it has succeeded.\n",
        "\n",
        "üìå **Action:** Set `pipelines_components_root` to the path of your pipelines-components repo (or set `PIPELINES_COMPONENTS_ROOT`). Ensure the pipeline package and dependencies are installed (e.g. `pip install kfp kfp-components` from pipelines-components).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d2723a3",
      "metadata": {},
      "source": [
        "### Add pipeline package and import\n",
        "\n",
        "Add the pipelines-components root to `sys.path` so we can import the pipeline function, then compile and submit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c72533",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Root of pipelines-components repo (directory that contains the 'pipelines' package)\n",
        "pipelines_components_root = os.environ.get(\n",
        "    \"PIPELINES_COMPONENTS_ROOT\",\n",
        "    \"/path/to/pipelines-components\",  # set this or set env PIPELINES_COMPONENTS_ROOT\n",
        ")\n",
        "if pipelines_components_root not in sys.path:\n",
        "    sys.path.insert(0, pipelines_components_root)\n",
        "\n",
        "from kfp.compiler import Compiler\n",
        "from pipelines.training.automl.autogluon_tabular_training_pipeline import (\n",
        "    autogluon_tabular_training_pipeline,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57f83b4e",
      "metadata": {},
      "source": [
        "### Configuration\n",
        "\n",
        "Set pipeline parameters (S3 data location, label column, task type, top N models) and the experiment and run names for the new run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0c65283",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pipeline parameters (match autogluon_tabular_training_pipeline arguments)\n",
        "pipeline_params = {\n",
        "    \"train_data_secret_name\": \"s3-credentials\",\n",
        "    \"train_data_bucket_name\": \"my-data-bucket\",\n",
        "    \"train_data_file_key\": \"datasets/train.csv\",\n",
        "    \"label_column\": \"target\",\n",
        "    \"task_type\": \"binary\",  # or \"multiclass\", \"regression\"\n",
        "    \"top_n\": 3,\n",
        "}\n",
        "\n",
        "# Experiment name (grouping for runs)\n",
        "run_experiment_name = \"AutoML Titanic\"\n",
        "\n",
        "# Display name for this run\n",
        "run_display_name = \"Titanic survived prediction 0.1.0\"\n",
        "\n",
        "# Compiled pipeline YAML path\n",
        "pipeline_package_path = \"autogluon_tabular_training_pipeline.yaml\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56e019b3",
      "metadata": {},
      "source": [
        "### Compile and submit the pipeline\n",
        "\n",
        "Compile the pipeline to a YAML file, then create a KFP client (same connection as in **Monitor KFP run details**) and submit a new run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2fdd908",
      "metadata": {},
      "outputs": [],
      "source": [
        "compiler = Compiler()\n",
        "compiler.compile(\n",
        "    pipeline_func=autogluon_tabular_training_pipeline,\n",
        "    package_path=pipeline_package_path,\n",
        ")\n",
        "print(f\"Compiled pipeline to {pipeline_package_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ee0e103",
      "metadata": {},
      "outputs": [],
      "source": [
        "import kfp\n",
        "\n",
        "kubeflow_endpoint = os.environ.get(\"KF_PIPELINES_SA_ENDPOINT\", \"https://ds-pipeline-dspa-autox.apps.rosa.rhoai-dev.mfe3.p3.openshiftapps.com\")\n",
        "sa_token_path = os.environ.get(\"KF_PIPELINES_SA_TOKEN_PATH\", \"/var/run/secrets/kubernetes.io/serviceaccount/token\")\n",
        "sa_ca_cert = os.environ.get(\"PIPELINES_SSL_SA_CERTS\", \"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\")\n",
        "\n",
        "if \"BEARER_TOKEN\" in os.environ:\n",
        "    bearer_token = os.environ[\"BEARER_TOKEN\"]\n",
        "elif os.path.isfile(sa_token_path):\n",
        "    with open(sa_token_path) as f:\n",
        "        bearer_token = f.read().rstrip()\n",
        "else:\n",
        "    raise RuntimeError(\"Set BEARER_TOKEN or KF_PIPELINES_SA_TOKEN_PATH\")\n",
        "\n",
        "ssl_ca_cert = sa_ca_cert if (os.path.isfile(sa_ca_cert) and \"svc\" in kubeflow_endpoint) else None\n",
        "\n",
        "run_client = kfp.Client(\n",
        "    host=kubeflow_endpoint,\n",
        "    existing_token=bearer_token,\n",
        "    ssl_ca_cert=ssl_ca_cert,\n",
        ")\n",
        "\n",
        "run_result = run_client.create_run_from_pipeline_package(\n",
        "    pipeline_file=pipeline_package_path,\n",
        "    arguments=pipeline_params,\n",
        "    run_name=run_display_name,\n",
        "    experiment_name=run_experiment_name,\n",
        ")\n",
        "\n",
        "submitted_run_id = run_result.run_id\n",
        "print(f\"Submitted run: {submitted_run_id}\")\n",
        "print(f\"Use this run_id in Monitor KFP run details or set run_id = '{submitted_run_id}' for leaderboard/download.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8ff506e-f1a3-4990-a979-7790a5105251",
      "metadata": {},
      "source": [
        "<a id=\"monitor-kfp-run-details\"></a>\n",
        "## Monitor KFP run details\n",
        "\n",
        "üìå **Action:** Set `kubeflow_endpoint`, `experiment_name`, and `run_name` to match your KFP pipeline and run. Ensure `KF_PIPELINES_SA_TOKEN_PATH` or `BEARER_TOKEN` is configured.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fe751dc-f097-4a7a-a895-9de6aedeb0ab",
      "metadata": {},
      "source": [
        "### initialize kfp client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "24b82d88-81df-461f-b5fd-2fb10c33acab",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to kfp: https://ds-pipeline-dspa-autox.apps.rosa.rhoai-dev.mfe3.p3.openshiftapps.com\n",
            "BEARER_TOKEN found as service account token\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import kfp\n",
        "\n",
        "kubeflow_endpoint = \"https://ds-pipeline-dspa-autox.apps.rosa.rhoai-dev.mfe3.p3.openshiftapps.com\"\n",
        "print(f\"Connecting to kfp: {kubeflow_endpoint}\")\n",
        "\n",
        "sa_token_path = os.environ[\"KF_PIPELINES_SA_TOKEN_PATH\"]\n",
        "sa_ca_cert = os.environ[\"PIPELINES_SSL_SA_CERTS\"]\n",
        "\n",
        "if \"BEARER_TOKEN\" in os.environ:\n",
        "    print(\"BEARER_TOKEN provided as environment variable\")\n",
        "    bearer_token = os.environ[\"BEARER_TOKEN\"]\n",
        "elif os.path.isfile(sa_token_path):\n",
        "    print(\"BEARER_TOKEN found as service account token\")\n",
        "    with open(sa_token_path) as f:\n",
        "        bearer_token = f.read().rstrip()\n",
        "\n",
        "if os.path.isfile(sa_ca_cert) and \"svc\" in kubeflow_endpoint:\n",
        "    print(\"CA Cert found in container\")\n",
        "    ssl_ca_cert = sa_ca_cert\n",
        "else:\n",
        "    ssl_ca_cert = None\n",
        "\n",
        "client = kfp.Client(\n",
        "    host=kubeflow_endpoint,\n",
        "    existing_token=bearer_token,\n",
        "    ssl_ca_cert=ssl_ca_cert,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70dc3390-b24b-4a7e-b92c-e2e14ea8b237",
      "metadata": {},
      "source": [
        "### get pipeline details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "34cb4928-6f51-41c8-a2c1-d16ef21d47d1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "components ['autogluon-models-full-refit', 'automl-data-loader', 'for-loop-1', 'leaderboard-evaluation', 'models-selection', 'train-test-split']\n"
          ]
        }
      ],
      "source": [
        "pipeline_name = \"autogluon-tabular-training-pipeline\"\n",
        "pipeline_id = client.get_pipeline_id(pipeline_name)\n",
        "component_names = []\n",
        "\n",
        "for ver in client.list_pipeline_versions(pipeline_id=pipeline_id).to_dict()[\"pipeline_versions\"]:\n",
        "    components = ver[\"pipeline_spec\"][\"pipeline_spec\"][\"components\"]\n",
        "    for key, value in components.items():\n",
        "        component_names.append(key.removeprefix(\"comp-\"))\n",
        "\n",
        "print(\"components\", component_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8014b2e-60db-4046-918f-50ee137f9651",
      "metadata": {},
      "source": [
        "### list experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a8420ce9-5f1e-4c39-890d-6b60b64b1ddc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "experiment_id 4894852c-ab35-4f2e-b390-5e9c28bdd58e\n"
          ]
        }
      ],
      "source": [
        "experiment_name = \"AutoML Titanic\"\n",
        "experiment_id = None\n",
        "\n",
        "for exp in client.list_experiments().to_dict()[\"experiments\"]:\n",
        "    if exp[\"display_name\"] == experiment_name:\n",
        "        experiment_id = exp[\"experiment_id\"]\n",
        "    \n",
        "print(\"experiment_id\", experiment_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87528fc3-b40e-46e5-ba91-3704b08a87ec",
      "metadata": {},
      "source": [
        "### get run details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "fa7f736d-0b5c-4988-87a5-4d1a5cde0873",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Titanic survived prediction 0.1.0 None\n"
          ]
        }
      ],
      "source": [
        "run_name = \"Titanic survived prediction 0.1.0\"\n",
        "run_id = None\n",
        "runs = client.list_runs(experiment_id=experiment_id)\n",
        "\n",
        "for run in runs.to_dict()['runs']:\n",
        "    if run['display_name'] == run_name:\n",
        "        run_id = run['run_id']\n",
        "    \n",
        "print(run_name, run_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e475776-a2ae-40a5-a1cd-9ebc54b8a247",
      "metadata": {},
      "source": [
        "### check run status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e6cc90b0-4772-45e6-878f-e6e814021b87",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "autogluon-models-full-refit SUCCEEDED\n",
            "autogluon-models-full-refit SUCCEEDED\n",
            "train-test-split SUCCEEDED\n",
            "automl-data-loader SUCCEEDED\n",
            "autogluon-models-full-refit SUCCEEDED\n",
            "for-loop-1 SUCCEEDED\n",
            "models-selection SUCCEEDED\n",
            "leaderboard-evaluation SUCCEEDED\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "{'run_id': 'd3998ea8-2be4-4f86-8598-85d46b0038c9',\n",
        "   'task_id': 'b092fef4-11cd-49d3-b3ba-6052bd01f6fd',\n",
        "   'display_name': 'iteration-item-driver',\n",
        "   'create_time': datetime.datetime(2026, 1, 27, 9, 50, 29, tzinfo=tzlocal()),\n",
        "   'start_time': datetime.datetime(2026, 1, 27, 9, 56, 15, tzinfo=tzlocal()),\n",
        "   'end_time': datetime.datetime(2026, 1, 27, 9, 56, 18, tzinfo=tzlocal()),\n",
        "   'executor_detail': None,\n",
        "   'state': 'SUCCEEDED',\n",
        "   'execution_id': None,\n",
        "   'error': None,\n",
        "   'inputs': None,\n",
        "   'outputs': None,\n",
        "   'parent_task_id': None,\n",
        "\"\"\"\n",
        "run = client.get_run(run_id=run_id)\n",
        "run_details = run.run_details.to_dict()\n",
        "\n",
        "for task in run_details['task_details']:\n",
        "    if task[\"display_name\"] and task[\"display_name\"] in component_names:\n",
        "        print(task[\"display_name\"], task[\"state\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00cc5969-0f9b-406d-a6e9-dce42ed64331",
      "metadata": {},
      "source": [
        "<a id=\"display-leaderboard\"></a>\n",
        "## Display leaderboard\n",
        "\n",
        "üìù **Note:** Ensure the S3 connection is added to the workbench so the notebook can access the results (e.g. `AWS_S3_ENDPOINT`, `AWS_S3_BUCKET`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9be1f501-02e4-4107-906b-8f19448768bd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>balanced_accuracy</th>\n",
              "      <th>mcc</th>\n",
              "      <th>roc_auc</th>\n",
              "      <th>f1</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1_FULL</td>\n",
              "      <td>0.903587</td>\n",
              "      <td>0.894618</td>\n",
              "      <td>0.798385</td>\n",
              "      <td>0.964869</td>\n",
              "      <td>0.876081</td>\n",
              "      <td>0.904762</td>\n",
              "      <td>0.849162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LightGBMXT_BAG_L2_FULL</td>\n",
              "      <td>0.903587</td>\n",
              "      <td>0.894618</td>\n",
              "      <td>0.798385</td>\n",
              "      <td>0.964869</td>\n",
              "      <td>0.876081</td>\n",
              "      <td>0.904762</td>\n",
              "      <td>0.849162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NeuralNetFastAI_BAG_L4_FULL</td>\n",
              "      <td>0.903587</td>\n",
              "      <td>0.894618</td>\n",
              "      <td>0.798385</td>\n",
              "      <td>0.964869</td>\n",
              "      <td>0.876081</td>\n",
              "      <td>0.904762</td>\n",
              "      <td>0.849162</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import boto3\n",
        "import os\n",
        "from IPython.display import HTML\n",
        "\n",
        "s3 = boto3.resource('s3', endpoint_url=os.environ['AWS_S3_ENDPOINT'])\n",
        "bucket = s3.Bucket(os.environ['AWS_S3_BUCKET'])\n",
        "prefix = os.path.join(pipeline_name, run_id)\n",
        "leaderboard_prefix = os.path.join(prefix, 'leaderboard-evaluation')\n",
        "leaderboard_artifact_name = 'html_artifact'\n",
        "\n",
        "for obj in bucket.objects.filter(Prefix=leaderboard_prefix):\n",
        "    if leaderboard_artifact_name in obj.key:\n",
        "        bucket.download_file(obj.key, leaderboard_artifact_name)\n",
        "\n",
        "HTML(leaderboard_artifact_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54525a94-7799-41cc-822e-91bae88b3b78",
      "metadata": {},
      "source": [
        "<a id=\"download-trained-model\"></a>\n",
        "## Download trained model\n",
        "\n",
        "üìå **Action:** Set `model_to_download` to the model you want to download (must match a name from the leaderboard **model** column).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "641b68b8-8275-485b-8541-89405127b6aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_to_download = \"LightGBMXT_BAG_L2_FULL\"\n",
        "\n",
        "full_refit_prefix = os.path.join(prefix, \"autogluon-models-full-refit\")\n",
        "best_model_subpath = os.path.join(\"model_artifact\", model_to_download)\n",
        "local_dir = None  # set to a path to download under a specific local directory\n",
        "best_model_path = None\n",
        "\n",
        "for obj in bucket.objects.filter(Prefix=full_refit_prefix):\n",
        "    if best_model_subpath not in obj.key or obj.key.endswith(\"/\"):\n",
        "        continue\n",
        "    target = (\n",
        "        obj.key\n",
        "        if local_dir is None\n",
        "        else os.path.join(local_dir, os.path.relpath(obj.key, full_refit_prefix))\n",
        "    )\n",
        "    parent = os.path.dirname(target)\n",
        "    if not os.path.exists(parent):\n",
        "        os.makedirs(parent)\n",
        "    bucket.download_file(obj.key, target)\n",
        "    best_model_path = obj.key\n",
        "\n",
        "if best_model_path is not None:\n",
        "    best_model_path = os.path.join(\n",
        "        best_model_path.split(model_to_download)[0], model_to_download\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6686ef6f-3251-43fa-bc9d-a9e911c7908c",
      "metadata": {},
      "source": [
        "<a id=\"load-the-model\"></a>\n",
        "## Load the model\n",
        "\n",
        "Load the trained model as a TabularPredictor object.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d8cf73cc-d12e-4255-b0a6-9240c5e6f7a1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.12/site-packages (from requests->autogluon.core==1.3.1->autogluon.tabular==1.3.1) (2025.11.12)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install autogluon.tabular==1.3.1 | tail -n 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9ebc576f-17eb-49a7-8dcb-6b237dcc2218",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/opt/app-root/lib64/python3.12/site-packages/autogluon/common/utils/utils.py:97: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "Found 1 mismatches between original and current metadata:\n",
            "\tWARNING: AutoGluon Python version mismatch (original=3.11, current=3.12)\n"
          ]
        }
      ],
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "predictor = TabularPredictor.load(best_model_path, require_py_version_match=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "064c76e4-1b44-4bba-8f2b-3178633a326a",
      "metadata": {},
      "source": [
        "### Score data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d6955253-1891-4ff7-8b3e-ffa338d928f8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.25</td>\n",
              "      <td></td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.90</td>\n",
              "      <td></td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Pclass                     Name  Sex  Age  SibSp  Parch  \\\n",
              "0            1       3  Braund, Mr. Owen Harris    0   22      1      0   \n",
              "1            2       1   Heikkinen, Miss. Laina    1   26      0      0   \n",
              "\n",
              "             Ticket  Fare Cabin Embarked  \n",
              "0         A/5 21171  7.25              S  \n",
              "1  STON/O2. 3101282  7.90              C  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "score_data = {\n",
        "    \"PassengerId\": [1, 2], \n",
        "    \"Pclass\": [3, 1], \n",
        "    \"Name\": [\"Braund, Mr. Owen Harris\", \"Heikkinen, Miss. Laina\"], \n",
        "    \"Sex\": [0, 1],\n",
        "    \"Age\": [22, 26],\n",
        "    \"SibSp\": [1, 0],\n",
        "    \"Parch\": [0, 0],\n",
        "    \"Ticket\": [\"A/5 21171\", \"STON/O2. 3101282\"],\n",
        "    \"Fare\": [7.25, 7.9],\n",
        "    \"Cabin\": [\"\", \"\"],\n",
        "    \"Embarked\": [\"S\", \"C\"]\n",
        "}\n",
        "score_df = pd.DataFrame(data=score_data)\n",
        "score_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f07e1d71-85e8-4484-877a-5af40547de4f",
      "metadata": {},
      "source": [
        "### Predict the Survived value for score records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8441133b-2984-4ea9-92a1-4e427d25ee1b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.787024</td>\n",
              "      <td>0.212976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.039443</td>\n",
              "      <td>0.960557</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1\n",
              "0  0.787024  0.212976\n",
              "1  0.039443  0.960557"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict_proba(score_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ee6d313-4612-4fb9-bee2-b2dcc83772ef",
      "metadata": {},
      "source": [
        "<a id=\"summary-and-next-steps\"></a>\n",
        "## Summary and next steps\n",
        "\n",
        "**Summary:** This notebook monitored KFP run details, displayed the experiment leaderboard, downloaded a trained AutoGluon model from S3, and ran predictions on sample data.\n",
        "\n",
        "**Next steps:**\n",
        "- Use the predictor notebook to load and score from a different run (set `pipeline_name`, `run_id`, and `model_name`).\n",
        "- Run predictions on your own data (ensure columns match the training schema).\n",
        "- Optionally save the predictor locally with `predictor.save(\"path/to/dir\")` for offline use.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "automl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
